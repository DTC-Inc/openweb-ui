# Open-WebUI Environment Configuration
# Copy this file to .env and modify the values as needed

# =============================================================================
# BASIC CONFIGURATION
# =============================================================================

# Container naming prefix
CONTAINER_NAME_PREFIX=openwebui

# Timezone configuration
TZ=America/New_York

# User and Group IDs for file permissions (optional - commented out for simplicity)
# PUID=1000
# PGID=1000

# =============================================================================
# OPEN-WEBUI CONFIGURATION
# =============================================================================

# Open-WebUI version/tag
OPEN_WEBUI_VERSION=main

# Port for Open-WebUI web interface
OPEN_WEBUI_PORT=3000

# Secret key for sessions (generate a random string)
WEBUI_SECRET_KEY=your-secret-key-here

# Authentication settings
WEBUI_AUTH=true
ENABLE_SIGNUP=true
DEFAULT_USER_ROLE=pending

# OAuth/OpenID Connect configuration for Entra ID SSO
OAUTH_CLIENT_ID=
OAUTH_CLIENT_SECRET=
OPENID_PROVIDER_URL=
OAUTH_SCOPES=openid email profile
OAUTH_PROVIDER_NAME=Entra ID
OAUTH_USERNAME_CLAIM=preferred_username
OAUTH_EMAIL_CLAIM=email
OAUTH_PICTURE_CLAIM=picture
OAUTH_MERGE_ACCOUNTS_BY_EMAIL=false
ENABLE_OAUTH_SIGNUP=true

# Memory limit for Open-WebUI container
OPEN_WEBUI_MEMORY_LIMIT=2G

# =============================================================================
# AI MODEL PROVIDER API KEYS
# =============================================================================

# OpenAI API Key (optional)
OPENAI_API_KEY=

# Anthropic API Key (optional)
ANTHROPIC_API_KEY=

# =============================================================================
# OLLAMA CONFIGURATION (LOCAL AI MODELS)
# =============================================================================

# Enable/disable Ollama service (1 to enable, 0 to disable)
ENABLE_OLLAMA=1

# Ollama version/tag
OLLAMA_VERSION=latest

# Ollama port
OLLAMA_PORT=11434

# GPU configuration for Ollama
OLLAMA_GPU_COUNT=0
OLLAMA_DEVICE_GPU=/dev/nvidia0:/dev/nvidia0

# Model keep-alive duration (how long to keep models in memory)
OLLAMA_KEEP_ALIVE=5m



# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Enable/disable PostgreSQL (1 to enable, 0 to disable - uses SQLite by default)
ENABLE_POSTGRES=1

# PostgreSQL version
POSTGRES_VERSION=15-alpine

# PostgreSQL credentials
POSTGRES_USER=openwebui
POSTGRES_PASSWORD=changeme
POSTGRES_DB=openwebui

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================

# Enable/disable Redis (1 to enable, 0 to disable)
ENABLE_REDIS=1

# =============================================================================
# NETWORK CONFIGURATION
# =============================================================================

# Network names
OPEN_WEBUI_APP_NETWORK=openwebui_app
OPEN_WEBUI_MODELS_NETWORK=openwebui_models
OPEN_WEBUI_DB_NETWORK=openwebui_db

# =============================================================================
# TRAEFIK DOMAIN CONFIGURATION
# =============================================================================

# Public domain (accessible from anywhere)
OPEN_WEBUI_PUBLIC_DOMAIN=openwebui.yourdomain.com

# Private domain (accessible only from whitelisted IPs)
OPEN_WEBUI_PRIVATE_DOMAIN=openwebui-private.yourdomain.com

# Certificate resolver (default: letsencrypt)
OPEN_WEBUI_CERT_RESOLVER=letsencrypt

# =============================================================================
# CLOUDFLARE TUNNEL CONFIGURATION (OPTIONAL)
# =============================================================================

# Enable/disable Cloudflare tunnel (1 to enable, 0 to disable)
ENABLE_OPEN_WEBUI_CLOUDFLARED=0

# Cloudflare tunnel token
OPEN_WEBUI_CLOUDFLARE_TUNNEL_TOKEN=

 